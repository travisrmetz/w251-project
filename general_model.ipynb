{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "general_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhWgnKiqj8tG",
        "colab_type": "text"
      },
      "source": [
        "# Automating Marine Celestial Navigation with Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty7mp8tWkbuP",
        "colab_type": "text"
      },
      "source": [
        "## Mount the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UezWzO8Ui7zs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8e64b086-119f-4523-b5e0-af504e700504"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# gttmw251@gmail.com\n",
        "# StarNN251!"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwgNzXNjRrQ1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNd0zcp-ke0s",
        "colab_type": "text"
      },
      "source": [
        "## Load useful packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzXCZEnCjRtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxCYLLJekiVI",
        "colab_type": "text"
      },
      "source": [
        "## Define functions to load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZTE4ySVkrf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(image_path, dim=(224,224)):\n",
        "  \"\"\"\n",
        "  Loads a single image as a Numpy array and resizes it as\n",
        "  desired.  The default dimensions are consistent with\n",
        "  those expected by the VGG models.  \n",
        "\n",
        "  Args:\n",
        "    image_path: str pointing to the file\n",
        "\n",
        "    dim: Two-element tuple giving the desired height\n",
        "         and width of the processed image\n",
        "\n",
        "  Returns:\n",
        "    image:  A single-channel Numpy array\n",
        "  \"\"\"\n",
        "\n",
        "  image = cv2.imread(image_path, 0)\n",
        "  image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
        "  return image\n",
        "\n",
        "\n",
        "def build_input(image_dir):\n",
        "  \"\"\"\n",
        "  Loads all of the images into a single numpy array.\n",
        "  Assumes that there are 101 equally-spaced images\n",
        "  spanning lattitudes from 35N to 45N.  \n",
        "\n",
        "  Args:\n",
        "    image_dir: str giving name of the image directory\n",
        "\n",
        "  Returns:\n",
        "    X:  A 3-dimensional numpy array containing the\n",
        "        images. Image height and width are set by\n",
        "        `load_images` and default to 224 x 224.\n",
        "    \n",
        "    y:  A 1-dimensional numpy array of target lattitudes.\n",
        "  \"\"\"\n",
        "  X = []\n",
        "  file_paths = os.listdir(image_dir)\n",
        "  for path in file_paths:\n",
        "    image = load_image(os.path.join(image_dir, path))\n",
        "    X.append(image.flatten())\n",
        "  return np.array(X) / 255\n",
        "\n",
        "\n",
        "def parse_path(image_path):\n",
        "  \"\"\"\n",
        "  Parses a file name, extracting lattitude, longitude,\n",
        "  and date/time.\n",
        "\n",
        "  Args:\n",
        "    image_path: str giving name of a path to an image\n",
        "                file\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing lattitude, longitude and\n",
        "    date/time.\n",
        "  \"\"\"\n",
        "  # Cut '.png'\n",
        "  image_path = image_path[:-4]\n",
        "\n",
        "  # Split on '+'\n",
        "  lat, long, dtg = image_path.split('+')\n",
        "\n",
        "  lat = float(lat)\n",
        "  long = float(long)\n",
        "\n",
        "  return (lat, long, dtg)\n",
        "\n",
        "\n",
        "def parse_dir(image_dir):\n",
        "  \"\"\"\n",
        "  Reads a file name in a directory, parses them,\n",
        "  and places the data in numpy arrays.\n",
        "\n",
        "  Args:\n",
        "    image_path: str giving name of a path containing\n",
        "                image files\n",
        "\n",
        "  Returns:\n",
        "    lat:  a numpy array of lattitudes\n",
        "    long: a numpy array of longitudes\n",
        "    dtg:  a numpy array with elements of class\n",
        "          np.datetime64\n",
        "  \"\"\"\n",
        "  path_list  = os.listdir(image_dir)\n",
        "  tuple_list = [parse_path(i) for i in path_list]\n",
        "  lat        = np.array([j[0] for j in tuple_list])\n",
        "  long       = np.array([k[1] for k in tuple_list])\n",
        "  dtg        = np.array([np.datetime64(l[2]) for l in tuple_list])\n",
        "  return lat, long, dtg"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqFVJi6X1E1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/images'\n",
        "lat, long, dtg = parse_dir(data_path)\n",
        "X = build_input(data_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl-x81SY_Alt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "650aed48-4dd5-4fda-e949-5c9f8c7358a2"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134, 50176)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rQuQMlkCASN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34541d8d-0bce-4594-8bb2-01382cef484e"
      },
      "source": [
        "dtg[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.datetime64('2020-05-25T00:59:02')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuPUBaU-DRNt",
        "colab_type": "text"
      },
      "source": [
        "## Define a custom loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APP5ecR4DS7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def haversine_loss(y_true, y_pred):\n",
        "  # TODO: Remember that y_true and y_pred will be\n",
        "  # in the from of normalized lat and long...you will\n",
        "  # need to convert this to lat and long in radians.\n",
        "  # The following code assumes that this is done.\n",
        "  half_delta_lat  = (y_true[0] - y_pred[0]) / 2\n",
        "  half_delta_long = (y_true[1] - y_pred[1]) / 2\n",
        "  a = tf.sin(half_delta_lat) ** 2 + tf.cos(y_true[0]) * tf.cos(y_true[1]) + tf.sin(half_delta_long) ** 2\n",
        "  c = 2 * tf.atan2(tf.sqrt(a), tf.sqrt(1 - a))\n",
        "  R = 3440.065 # nautical miles\n",
        "  d = R * c\n",
        "  squared_d = tf.square(d)\n",
        "  return tf.reduce_mean(squared_d, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckMzEysjRmnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}